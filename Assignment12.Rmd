
---
output: 
  html_document:
  pdf_document: default
  word_document: default
title: "Assignment 12: Predictive Modeling - Part 3"
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](fa2021_assignment12.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Blackboard.

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


-------

1. Install the package `mlbench` and use the follows to import the data

```{r}
library(mlbench)
data(PimaIndiansDiabetes)
df <- PimaIndiansDiabetes
```

- Set seed to be 2020. 
- The target variable is `diabetes`
- Partition the data into 80% training and 20% testing.  

```{r}
library(caret)
df$diabetes = factor(df$diabetes)

set.seed(2020)
splitIndex <- createDataPartition(df$diabetes, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
```

-------

2. Use cross-validation of 30 folds to tune random forest (method='rf').  What is the `mtry` value that produces the greatest accuracy?

The 3 depth model had the highest accuracy.

```{r}
tuneGrid = expand.grid(mtry = 2:4)

trControl = trainControl(method = "cv",
                         number = 30)

forest_rf <- train(diabetes~., data=df_train, 
                                method = "rf", 
                                trControl = trControl,
                                tuneGrid = tuneGrid)

plot(forest_rf)
```
 
-------

3. Use cross-validation with of 30 folds to tune random forest (method='ranger').  What are the parameters that produce the greatest accuracy?
The extra trees model with a depth of 8 had the highest accuracy.

```{r}
trControl = trainControl(method = "cv",
                         number = 30)
tuneGrid = expand.grid(mtry = 2:4,
                       splitrule = c('gini', 'extratrees'),
                       min.node.size = c(1:10))

ranger_rf <- train(diabetes~., data=df_train, 
                                method = "ranger", 
                                trControl = trControl,
                                tuneGrid = tuneGrid)

plot(ranger_rf)
```

-------

4. Go to https://topepo.github.io/caret/available-models.html and pick a classification model.  Tune the classification model using cross-validation of 30 folds. 

```{r}
trControl = trainControl(method = "cv",
                         number = 30)
tuneGrid = expand.grid(k = 5:8)

knn <- train(diabetes~., data=df_train, 
                                method = "knn", 
                                trControl = trControl,
                                tuneGrid = tuneGrid)

plot(knn)
```

-------

5. Pick three models at [this link](https://topepo.github.io/caret/available-models.html) to compare using 15-fold cross validation method. Evaluate the accuracy of the final model on the test data. What is the best model?

The LDA is the best model because even though the mean of the Random Forest had a higher mean, the LDA had a smaller range.

``` {r}
trControl = trainControl(method = "cv",
                         number = 15)

tree <- train(diabetes~., data=df_train, 
                                method = "rpart2", 
                                trControl = trControl)

forest_ranger <- train(diabetes~., data=df_train, 
                    method = "ranger", 
                                trControl = trControl)

lda <- train(diabetes~., data=df_train, 
                                method = "lda", 
                                trControl = trControl)

results <- resamples(list('Decision Tree' = tree,
                          'Random Forest' = forest_ranger,
                          'LDA'= lda))
bwplot(results)

```

-------

6. Redo Question 5 on this following dataset. 

 - `Adult Census Income` dataset ([Link](https://www.kaggle.com/uciml/adult-census-income)) where the target variable is `income`
 -  `Credit card default` dataset ([link](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset)) where the target variable is `default.payment.next.month`
 
The decision had the highest accuracy and kappa, so out of these three choices, it is the best model.
 
``` {r}
library(tidyverse)
credit = read_csv("UCI_Credit_Card.csv")

colnames(credit)[25] <- "target"

library(randomForest)
credit$target = factor(credit$target)

library(caret)
set.seed(2020)
splitIndex <- createDataPartition(credit$target, p = .80, 
                                  list = FALSE)
credit_train <- credit[ splitIndex,]
credit_test <- credit[-splitIndex,]

trControl = trainControl(method = "cv",
                         number = 5)

tree <- train(target~., data=credit_train, 
                                method = "rpart2", 
                                trControl = trControl)

knn <- train(target~., data=credit_train, 
                    method = "knn", 
                                trControl = trControl)

kknn <- train(target~., data=credit_train, 
                                method = "kknn", 
                                trControl = trControl)

results <- resamples(list('Decision Tree' = tree,
                          'K Nearest Neighbor' = knn,
                          'KK Nearest Neighbor'= kknn))
bwplot(results) 
```